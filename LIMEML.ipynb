pip install lime

import lime
import lime.lime_tabular
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import numpy as np

# Assuming X_train, X_test, y_train, y_test are your training and testing data
# Assuming lr is your trained Logistic Regression model

# Define feature columns and predicted class
feature_columns = ['Age', 'Number of sexual partners', 'First sexual intercourse', 'Num of pregnancies',
                   'Smokes', 'Smokes (years)', 'Smokes (packs/year)', 'Hormonal Contraceptives',
                   'Hormonal Contraceptives (years)', 'IUD', 'IUD (years)', 'STDs', 'STDs (number)',
                   'STDs:condylomatosis', 'STDs:cervical condylomatosis', 'STDs:vaginal condylomatosis',
                   'STDs:vulvo-perineal condylomatosis', 'STDs:syphilis', 'STDs:pelvic inflammatory disease',
                   'STDs:genital herpes', 'STDs:molluscum contagiosum', 'STDs:AIDS', 'STDs:HIV',
                   'STDs:Hepatitis B', 'STDs:HPV', 'STDs: Number of diagnosis', 'STDs: Time since first diagnosis',
                   'STDs: Time since last diagnosis']
predicted_class = ['Dx:Cancer']

# Create a DataFrame from the data
X = df[feature_columns].values
y = df[predicted_class].values

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)

# Impute missing values
fill_values = SimpleImputer(missing_values=np.nan, strategy="mean")
X_train = fill_values.fit_transform(X_train)
X_test = fill_values.fit_transform(X_test)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train the Logistic Regression model
lr = LogisticRegression()
model = lr.fit(X_train, y_train)

# Make predictions on the test set
pred = model.predict(X_test)

# Print accuracy score
print(f"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%")

# Create a LIME explainer object
explainer = lime.lime_tabular.LimeTabularExplainer(X_train, mode="classification", feature_names=feature_columns)

# Define a function to predict using the Logistic Regression model
predict_fn = lambda x: model.predict_proba(x)

# Select a sample from the test set for explanation
sample_idx = 0  # Choose the index of the sample you want to explain

# Explain the prediction for the selected sample
exp = explainer.explain_instance(X_test[sample_idx], predict_fn, num_features=len(feature_columns))

# Print the explanation
exp.show_in_notebook()
